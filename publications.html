<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Trung Tran | publications</title>
  <meta name="description" content="Trung Tran's academic website.
">

  <!-- Open Graph -->


  <!-- Bootstrap & MDB -->
  <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg=="
    crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css"
    integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q=="
    crossorigin="anonymous" />

  <!-- Fonts & Icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"
    integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog=="
    crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css"
    integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg=="
    crossorigin="anonymous">
  <link rel="stylesheet" type="text/css"
    href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

  <!-- Code Syntax Highlighting -->
  <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

  <!-- Styles -->
  <link rel="shortcut icon" href="/assets/img/favicon.ico">
  <link rel="stylesheet" href="main.css">

  <link rel="canonical" href="publication">

  <!-- Theming-->



  <!-- MathJax -->
  <script defer type="text/javascript" id="MathJax-script"
    src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


</head>

<body class="fixed-top-nav sticky-bottom-footer">

  <!-- Header -->

  <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
      <div class="container">

        <a class="navbar-brand title font-weight-lighter" href="/">
          <span class="font-weight-bold">Trung Tran</span>
        </a>

        <!-- Navbar Toogle -->
        <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav"
          aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar top-bar"></span>
          <span class="icon-bar middle-bar"></span>
          <span class="icon-bar bottom-bar"></span>
        </button>
        <div class="collapse navbar-collapse text-right" id="navbarNav">
          <ul class="navbar-nav ml-auto flex-nowrap">
            <!-- About -->
            <li class="nav-item ">
              <a class="nav-link" href="index.html">
                About

              </a>
            </li>

            <!-- Blog -->
            <!--  <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
           -->
            <!-- Other pages -->



            <li class="nav-item active">
              <a class="nav-link" href="publications.html">
                Publications

                <span class="sr-only">(current)</span>

              </a>
            </li>

            <li class="nav-item ">
              <a class="nav-link" href="CV.pdf">
                CV
              </a>
            </li>

            <li class="nav-item ">
              <a class="nav-link" href="projects.html">
                Projects
              </a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

  </header>


  <!-- Content -->

  <div class="container mt-5">
    <div class="post">

      <header class="post-header">
        <h1 class="post-title">Publications</h1>
        <p class="post-description">(&#x2A) denotes equal contribution.</p>
      </header>

      <article>
        <!-- An up-to-date list is available on <a href="https://scholar.google.com/citations?user=VdlgOXoAAAAJ&hl=en" target="\_blank">Google Scholar</a> -->
        <div class="publications">
          <!-- start block-->
          <h2 class="year">2025</h2>
          <ol class="bibliography">
            <li>
              <div class="row">
                <div class="col-sm-2 abbr">
                  <abbr class="badge">Pre-print</abbr>
                </div>

                <div id="gao2020v1" class="col-sm-8">
                  <div class="title">CAMELLIA : BENCHMARKING CULTURAL BIASES
                    IN LLMS FOR ASIAN LANGUAGES</div>
                  <div class="author">Tarek Naous(1)
                    , Anagha Savit(1)
                    , Carlos Rafael Catalan(2)
                    , Geyang Guo(1)
                    , Jaehyeok Lee(3)
                    ,
                    Kyungdon Lee(3)
                    , Lheane Marie Dizon(2)
                    , Mengyu Ye(4)
                    , Neel Kothari(1)
                    , Sahajpreet Singh(5)
                    ,
                    Sarah Masud(6)
                    , Tanish Patwa(1)
                    , Trung Tanh Tran(7)
                    , Zohaib Khan(8)
                    , Alan Ritter(1)
                    ,
                    JinYeong Bak(3)
                    , Keisuke Sakaguchi(4)
                    , Tanmoy Chakraborty(9)
                    , Yuki Arase(10), Wei Xu(1)
                    <div></div>
                    (1) Georgia Institute of Technology, (2) Samsung R&D Institute Philippines,
                    (3) Sungkyunkwan University, (4)Tohoku University, (5) National University of Singapore,
                    (6) University of Copenhagen, (7) Takenote.ai, (8) University of Michigan,
                    (9) Indian Institute of Technology Delhi, (10) Institute of Science Tokyo</em>

                  </div>
                  <div class="periodical">
                    <em>Submitted to ICLR 2026
                  </div>

                  <div class="links">
                    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                    <a href="https://arxiv.org/pdf/2510.05291" class="btn btn-sm z-depth-0" role="button"
                      target="_blank">PDF</a>
                  </div>

                  <!-- Hidden abstract block -->
                  <div class="abstract hidden">
                    <p>As Large Language Models (LLMs) gain stronger multilingual capabilities, their
                      ability to handle culturally diverse entities becomes crucial. Prior work has shown
                      that LLMs often favor Western-associated entities in Arabic, raising concerns
                      about cultural fairness. Due to the lack of multilingual benchmarks, it remains
                      unclear if such biases also manifest in different non-Western languages. In this
                      paper, we introduce Camellia, a benchmark for measuring entity-centric cultural
                      biases in nine Asian languages spanning six distinct Asian cultures. Camellia includes 19,530
                      entities manually annotated for association with the specific Asian
                      or Western culture, as well as 2,173 naturally occurring masked contexts for entities derived from
                      social media posts. Using Camellia, we evaluate cultural biases
                      in four recent multilingual LLM families across various tasks such as cultural
                      context adaptation, sentiment association, and entity extractive QA. Our analyses show a struggle
                      by LLMs at cultural adaptation in all Asian languages, with
                      performance differing across models developed in regions with varying access to
                      culturally-relevant data. We further observe that different LLM families hold their
                      distinct biases, differing in how they associate cultures with particular sentiments.
                      Lastly, we find that LLMs struggle with context understanding in Asian languages,
                      creating performance gaps between cultures in entity extraction.
                    </p>
                  </div>

                  <!-- Hidden abstract block -->
                </div>
              </div>
            </li>
            <!-- end block-->
            <!-- start block-->
            <h2 class="year">2024</h2>
            <ol class="bibliography">
              <li>
                <div class="row">
                  <div class="col-sm-2 abbr">
                    <abbr class="badge">IGI</abbr>
                  </div>

                  <div id="gao2020v1" class="col-sm-8">
                    <div class="title">Charting the Ethical Course: Navigating AI Advancements in Communication
                      Education</div>
                    <div class="author">Huong Tra Le Nguyen*, <em>Trung Tran* </em>

                    </div>
                    <div class="periodical">
                      <em>In Sanae Elmoudden, Jason S. Wrench (editors) The Role of Generative AI in the Communication
                        Classroom
                    </div>

                    <div class="links">
                      <a href="https://www.igi-global.com/book/role-generative-communication-classroom/324756"
                        class="btn btn-sm z-depth-0" role="button" target="_blank">Book</a>
                    </div>

                    <!-- Hidden abstract block -->
                  </div>
                </div>
              </li>
              <li>
                <div class="row">
                  <div class="col-sm-2 abbr">
                    <abbr class="badge">IGI</abbr>
                  </div>

                  <div id="gao2020v1" class="col-sm-8">
                    <div class="title">Generative AI in terms of Its ethical problems for both teachers and learners:
                      Striking a balance
                    </div>
                    <div class="author">Huong Tra Le Nguyen*, <em>Trung Tran* </em>

                    </div>
                    <div class="periodical">
                      <em>In Shalin Hai-Jew (editors) Generative AI in Teaching and Learning
                    </div>

                    <div class="links">
                      <a href="https://www.igi-global.com/chapter/generative-ai-in-terms-of-its-ethical-problems-for-both-teachers-and-learners/334776"
                        class="btn btn-sm z-depth-0" role="button" target="_blank">Book</a>
                    </div>

                    <!-- Hidden abstract block -->
                  </div>
                </div>
              </li>
              <!-- end block-->

              <h2 class="year">2023</h2>
              <ol class="bibliography">
                <li>
                  <div class="row">
                    <div class="col-sm-2 abbr">
                      <abbr class="badge">IGI</abbr>
                    </div>

                    <div id="gao2020v1" class="col-sm-8">

                      <div class="title">Chatbots as motivational agents: Chatbots – The Value of a Digital Tool in
                        Pedagogy
                      </div>
                      <div class="author">Huong Tra Le Nguyen*, <em>Trung Tran* </em>

                      </div>
                      <div class="periodical">
                        <em>In Mohammad Amin et al (editors) Trends, Applications, and Challenges of Chatbot Technology
                      </div>

                      <div class="links">
                        <a href="https://www.igi-global.com/book/trends-applications-challenges-chatbot-technology"
                          class="btn btn-sm z-depth-0" role="button" target="_blank">Book</a>
                      </div>

                      <!-- Hidden abstract block -->
                    </div>
                  </div>
                </li>

                <h2 class="year">2021</h2>
                <ol class="bibliography">

                  <li>
                    <div class="row">
                      <div class="col-sm-2 abbr">
                        <abbr class="badge">ICICT</abbr>
                      </div>

                      <div id="gao2020v1" class="col-sm-8">

                        <div class="title">MAGNeto: An Efficient Deep Learning Method for the Extractive Tags
                          Summarization
                          Problem
                        </div>
                        <div class="author">Hieu Trong Phung (1 and 2), Anh Tuan Vu (1), Tung Dinh Nguyen (1), Lam Thanh
                          Do
                          (1 and 2), Giang Nam Ngo (1), <em>Trung Thanh Tran (1)</em>, Ngoc C. Lê (1 and 2) ((1) PIXTA
                          Vietnam, Hanoi, Vietnam. (2) Hanoi University of Science and Technology, Ha Noi, Viet Nam.)

                        </div>
                        <div class="periodical">
                          <em>The Seventh International Congress on Information and Communication Technology
                            (ICICT)</em>,
                          2021
                        </div>

                        <div class="links">
                          <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                          <a href="https://arxiv.org/pdf/2011.04349.pdf" class="btn btn-sm z-depth-0" role="button"
                            target="_blank">PDF</a>
                        </div>

                        <!-- Hidden abstract block -->
                        <div class="abstract hidden">
                          <p>In this work, we study a new image annotation
                            task named Extractive Tags Summarization (ETS).
                            The goal is to extract important tags from the context lying in an image and its
                            corresponding
                            tags.
                            We adjust some state-of-the-art deep learning models to utilize both visual and textual
                            information.
                            Our proposed solution consists of different widely
                            used blocks like convolutional and self-attention layers, together with a novel idea of
                            combining auxiliary loss functions and the gating mechanism to
                            glue and elevate these fundamental components and
                            form a unified architecture. Besides, we introduce
                            a loss function that aims to reduce the imbalance
                            of the training data and a simple but effective data
                            augmentation technique dedicated to alleviates the
                            effect of outliers on the final results. Last but not
                            least, we explore an unsupervised pre-training strategy to further boost the performance of
                            the
                            model
                            by making use of the abundant amount of available unlabeled data. Our model shows the good
                            results as 90% F1 score on the public NUS-WIDE
                            benchmark, and 50% F1 score on a noisy largescale real-world private dataset. Source code
                            for
                            reproducing the experiments is publicly available at:
                            <a href="https://github.com/pixta-dev/labteam">https://github.com/pixta-dev/labteam</a>.
                          </p>
                        </div>
                      </div>
                    </div>
                  </li>


                  <h2 class="year">2018</h2>
                  <ol class="bibliography">

                    <li>
                      <div class="row">
                        <div class="col-sm-2 abbr">


                          <abbr class="badge">Symposium</abbr>
                        </div>

                        <div id="nijkamp2020learning" class="col-sm-8">

                          <div class="title">An enhanced X-Vector Model for Noise-Robust, Text-Independent Speaker
                            Identification”. Panasonic Technology Symposium 2018</div>
                          <div class="author">
                            Truong, T.A, <em>Tran, T.T</em>, Vu, D.L

                          </div>

                          <div class="links">

                            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                            <a href="https://drive.google.com/file/d/1r6YIetbPoLlf9aIK7D5uSJeCwS0zvBHE/view"
                              class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
                          </div>

                          <!-- Hidden abstract block -->
                          <div class="abstract hidden">
                            <p>Our goal is todevelop an in-house, low-cost, scalable solution for closed-set
                              text-independent speaker identification. Driven
                              by Panasonic Corporation’s product development pathway, this research will be applicable a
                              wide range of consumer and
                              business-oriented products. Potential applications include recommendation systems for
                              smart
                              TVs, biometric authentication,
                              and automatic transcription for conference meetings, among others. We propose three
                              directions
                              to enhance identification
                              accuracy and noise-robustness: 1) retraining model on large open-source, noisy datasets;
                              2)
                              omitting excessive data
                              augmentation; 3) anew algorithm to detect non-voice samples. Our enhanced model achieves
                              an
                              increase in identification
                              accuracy by 9% compared to existing state-of-the-art open-source solutions, and achieves
                              non-voice detection accuracy of
                              97%. We are incorporating the speaker identification solution into a product prototype
                              targeted at the Vietnamese B2B and
                              B2C market.</p>
                          </div>

                        </div>
                      </div>
                    </li>



                  </ol>


                  <h2 class="year">2014</h2>
                  <ol class="bibliography">

                    <li>
                      <div class="row">
                        <div class="col-sm-2 abbr">
                          <abbr class="badge">ComNavi-14</abbr>
                        </div>

                        <div id="xie2019representation" class="col-sm-8">
                          <div class="title">Monitoring scintillations effects over Vietnam by means of a GNSS software
                            receiver</div>
                          <div class="periodical">
                            Workshop Communications and Navigations for the Development of Vietnam’s Marine Economy 2014
                          </div>

                          <div class="author">
                            <em>Tran, T.T</em>, Romero, R, Dovis, F

                          </div>

                          <!-- Hidden abstract block -->
                          <div class="abstract hidden">
                            <p>Learning representations of data is an important problem in statistics and machine
                              learning.
                              While the origin of learning representations can be traced back to factor analysis and
                              multidimensional scaling in statistics, it has become a central theme in deep learning
                              with
                              important applications in computer vision and computational neuroscience. In this article,
                              we
                              review recent advances in learning representations from a statistical perspective. In
                              particular, we review the following two themes: (a) unsupervised learning of vector
                              representations and (b) learning of both vector and matrix representations.</p>
                          </div>
                        </div>
                      </div>
                    </li>
                  </ol>


                  <h2 class="year">2013</h2>
                  <ol class="bibliography">

                    <li>
                      <div class="row">
                        <div class="col-sm-2 abbr">
                          <abbr class="badge">IEEE</abbr>
                        </div>

                        <div id="gao2018learning" class="col-sm-8">
                          <div class="title">Recent results in receiving and decoding signals from the Beidou system
                          </div>
                          <div class="author">
                            Duc Minh Truong*; <em>Trung Thanh Tran*</em>; Thuan Dinh Nguyen; Tung Hai Ta

                          </div>
                          <div class="periodical">
                            2013 International Conference on Localization and GNSS (ICL-GNSS)
                          </div>

                          <div class="links">
                            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                            <a href="https://ieeexplore.ieee.org/document/6577255?arnumber=6577255"
                              class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
                          </div>

                          <!-- Hidden abstract block -->
                          <div class="abstract hidden">
                            <p>Since December 27, 2012, the Beidou Navigation Satellite System officially started to
                              operate. This event is a great opportunity for researchers in South East of Asia to
                              receive
                              and analyze the Beidou signals. After the official statement, the researchers at NAVIS
                              centre
                              monitored the broadcasted signal by using NAVISOFT- our Software Radio Receiver. This
                              paper
                              shows the analysis on the navigation message that was broadcasted by the Beidou satellites
                              on
                              the B1I bandwidth. In general, we were able to observe a valid ephemeris data on visible
                              satellites. The successful PVT computation by using combinations of GEO and MEO/IGSO in
                              static
                              condition through code-phase measurements is indicated in this paper.
                            </p>
                          </div>
                        </div>
                      </div>
                    </li>
                  </ol>
        </div>
      </article>
    </div>
  </div>
  <!-- Footer -->
</body>

<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"
  integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg=="
  crossorigin="anonymous"></script>

<!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js"
  integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A=="
  crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"
  integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ=="
  crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js"
  integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw=="
  crossorigin="anonymous"></script>


<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="./js/mansory.js" type="text/javascript"></script>





<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-180825462-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-180825462-1');
</script>


<!-- Load Common JS -->
<script src="./js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="./js/dark_mode.js"></script>


</html>